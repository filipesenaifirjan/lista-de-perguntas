# lista-de-perguntas
lista de perguntas do curso de python

Python e ciência de dados

Pergunta comum:

O que é Python e por que é amplamente usado em ciência de dados? 

Python é uma linguagem de programação popular na ciência de dados devido à sua flexibilidade, legibilidade, 
facilidade de uso e rapidez na sua leitura(execução e desempenho). Além disso, possui uma grande quantidade de bibliotecas específicas 
para análise de dados, visualização e machine learning, o que torna mais fácil e eficiente a 
realização de tarefas relacionadas à ciência de dados. Uma outra característica é que ela é descrita como
entendida e orientada para o objeto principal. Uma linguagem de programação de ponta que possui semântica dinâmica



Quais são as principais bibliotecas em Python para análise de dados, processamento de dados e visualização?

Vou citar 3 exemplos:
Pandas: Oferece estruturas de dados e ferramentas de análise de alto desempenho, ideal para manipulação e preparação de dados.
NumPy: Fornece suporte para arrays multidimensionais e funções matemáticas de alto desempenho, sendo amplamente usado para processamento numérico.
Plotly: É uma biblioteca interativa que permite criar visualizações interativas, como gráficos de dispersão 3D, gráficos de barras animados e dashboards interativos.



Quais são os princípios básicos do aprendizado de máquina e como aplicá-los usando python?

Os princípios básicos do aprendizado de máquina envolvem a coleta e preparação de dados, a escolha do algoritmo adequado, 
o treinamento do modelo, a avaliação do desempenho e a aplicação do modelo em dados não vistos. 
Alguns passos comuns incluem: importar bibliotecas necessárias, carregar os dados, dividir os dados em conjuntos de 
treinamento e teste, selecionar e treinar o modelo, avaliar o desempenho do modelo e, finalmente, 
usar o modelo para fazer previsões em novos dados.
Uma outra característica é que ele é muito fácil de usar e de ser entendido pelos usuários. 
Os usuários podem lê-lo com muita facilidade, sem problemas, pois a taxa de legibilidade é muito clara.



O que é deep learning e como construir redes neurais usando python?

Deep learning é uma técnica avançada de aprendizado de máquina que utiliza redes neurais artificiais com várias camadas. 
Essas redes são projetadas para aprender automaticamente padrões e características complexas dos dados.



Quais são as alternativas ao python para ciencias de dados?

Seque algumas alternativas(3 exemplos)
Java
Java é conhecida como a linguagem de programação mais usada e famosa. 
É conhecido por usar uma plataforma de programação de servidor lateral e é um programa de back-end. 
É melhor usado para computar aplicativos de desktop, vários jogos e cálculos matemáticos.

PHP
PHP é baseado no escritor de código de programação do lado do servidor, que é usado ou colocado dentro do HTML. 
Ele é feito para realizar conteúdo ativo, registros, busca de reuniões e até mesmo moldar sites inteiros de comércio eletrônico. 
Ele é combinado por uma soma de arquivos gerais com MySQL Improved, PostgreSQL, Oracle, Sybase, Informix e Microsoft SQL Server.

TypeScript
TypeScript é uma linguagem de programação que foi estabelecida e preservada pela Microsoft. É um conjunto superior sintático orientado
a regras da linguagem JavaScript e melhora a escrita de código estático eletivo para a linguagem. 
O TypeScript destina-se ao progresso de grandes aplicativos da Web e a compilação trans para JavaScript.

Especificamente para ciências de dados, temos outras como:
(novamente mostrarei 3 exemplos)
R
R é uma linguagem de programação especialmente voltada para análise estatística e gráficos. 
É amplamente utilizado na comunidade de ciência de dados devido à sua grande quantidade de pacotes estatísticos e visualização de dados.

Julia 
é uma linguagem de programação de alto desempenho projetada para computação científica e análise de dados. 
Ela oferece uma combinação de velocidade e facilidade de uso, com uma sintaxe semelhante à do Python.

Scala com Spark 
Scala é uma linguagem de programação que pode ser usada em conjunto com o Apache Spark, 
um poderoso framework de processamento distribuído. Essa combinação é popular para o processamento de big data e análise de dados em larga escala.





